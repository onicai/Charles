{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify we're in the Conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "import pprint\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to list storyBooks with Diggy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# File paths\n",
    "input_file = \"storybookNFTs.json\"\n",
    "output_json_file = \"9-diggy.json\"\n",
    "output_csv_file = \"9-diggy.csv\"\n",
    "\n",
    "diggy_data = []\n",
    "counter = 1\n",
    "\n",
    "# Token ID (constant for all entries)\n",
    "token_id = \"https://syhes-kiaaa-aaaaj-azxda-cai.raw.icp0.io/?tokenid=psbym-7ykor-uwiaa-aaaaa-cigny-yaqca-aaaah-a\"\n",
    "\n",
    "# Read the JSON data\n",
    "with open(input_file, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Loop over the doublepages and collect entries with 'Diggy' or 'diggy'\n",
    "for nft_index, nft in enumerate(data):\n",
    "    for page_index, page in enumerate(nft.get(\"doublepages\", [])):\n",
    "        if \"Diggy\" in page[\"prompt\"] or \"diggy\" in page[\"prompt\"]:\n",
    "            diggy_data.append({\n",
    "                \"counter\": counter,\n",
    "                \"nft_id\": nft_index,\n",
    "                \"page_id\": page_index + 1,\n",
    "                \"imageURL\": page[\"imageUrl\"],\n",
    "                \"prompt\": page[\"prompt\"],\n",
    "                \"tokenid\": token_id\n",
    "            })\n",
    "            counter += 1\n",
    "\n",
    "# Write to JSON file\n",
    "with open(output_json_file, \"w\") as json_file:\n",
    "    json.dump(diggy_data, json_file, indent=4)\n",
    "\n",
    "# Write to CSV file\n",
    "with open(output_csv_file, \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=[\"counter\", \"nft_id\", \"page_id\", \"imageURL\", \"prompt\", \"tokenid\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(diggy_data)\n",
    "\n",
    "print(f\"Processed {len(diggy_data)} entries containing 'Diggy' or 'diggy'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charles-nftData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
