{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify we're in the Conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "import pprint\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to list storyBooks with Diggy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Load the JSON file\n",
    "with open('storybookNFTs.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize the diggy dictionary and counter\n",
    "diggy = []\n",
    "counter = 1\n",
    "\n",
    "# Loop through the JSON structure\n",
    "for doublepages_index, item in enumerate(data):\n",
    "    for page_index, page in enumerate(item[\"doublepages\"]):\n",
    "        if 'diggy' in page[\"prompt\"].lower():\n",
    "            nft_id = doublepages_index\n",
    "            page_id = page_index + 1\n",
    "            diggy_entry = {\n",
    "                \"counter\": counter,\n",
    "                \"nft_id\": nft_id,\n",
    "                \"page_id\": page_id,\n",
    "                \"nft-thumbnail\": \"placeholder\",  # Replace with actual thumbnail if needed\n",
    "                \"page\": \"placeholder\",          # Replace with actual page if needed\n",
    "                \"prompt\": page[\"prompt\"],\n",
    "                \"ordinal\": f\"https://bioniq.io/collection/charles/ordinals?search={nft_id}&filters=Status-1,2\",\n",
    "                \"tokenid\": \"https://syhes-kiaaa-aaaaj-azxda-cai.raw.icp0.io/?tokenid=psbym-7ykor-uwiaa-aaaaa-cigny-yaqca-aaaah-a\"\n",
    "            }\n",
    "            diggy.append(diggy_entry)\n",
    "            counter += 1\n",
    "\n",
    "# Write the diggy dictionary to a JSON file\n",
    "with open('9-diggy.json', 'w') as json_file:\n",
    "    json.dump(diggy, json_file, indent=4)\n",
    "\n",
    "# Write the diggy dictionary to a CSV file\n",
    "csv_headers = [\"counter\", \"nft_id\", \"page_id\", \"nft-thumbnail\", \"page\", \"prompt\", \"ordinal\", \"tokenid\"]\n",
    "\n",
    "with open('9-diggy.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=csv_headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(diggy)\n",
    "\n",
    "print(\"Files '9-diggy.json' and '9-diggy.csv' have been successfully created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charles-nftData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
